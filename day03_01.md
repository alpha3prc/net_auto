---
marp: true
theme: gaia
size: 16:9
headingDivider: [2,3]
paginate: true
---

## **04**

- urllib模块

## **urllib基础**

<!-- _class: lead -->

## **urllib 简介**

*   在Python2版本中，有urllib和urllib2两个库可以用来实现request的发送。而在Python3中，已经不存在urllib2这个库了，统一为urllib

*   urllib中包括了四个模块
    *   urllib.request可以用来发送request和获取request的结果
    *    urllib.error包含了urllib.request产生的异常
    *    urllib.parse用来解析和处理URL
    *    urllib.robotparse用来解析页面的robots.txt文件

### 试一下

```bash
python3
```

```python
from urllib import request
html= request.urlopen('http://www.baidu.com')
html.read(10)
html.readline()
html.readlines()
```

## **爬取网页**

*   先需要导入用到的模块：urllib.request

*   在导入了模块之后，我们需要使用urllib.request.urlopen打开并爬取一个网页

*   读取内容常见的有3种方式：
    *   $\checkmark$ read()读取文件的全部内容，与readlines()不同的是，read()会把读取到的内容赋给一个字符串变量。
    *   $\checkmark$ readlines()读取文件的全部内容，readlines()会把读取到的内容赋值给一个列表变量。
    *   $\checkmark$ readline()读取文件的一行内容。

### 试一下

```python
html= request.urlopen('http://www.baidu.com')
with open('/tmp/baidu.html','wb') as fobj:
    fobj.write(html.read())
```

## **案例6：爬取网页**

1.  爬取的网页为http://www.163.com
2.  保存的文件名为/tmp/163.html

## **下载网络资源**

*   urllib不仅可以下载网页，其他网络资源均可下载

*   有些文件比较大，需要像读取文件一样，每次读取一部分数据

```python
import urllib.request
html = urllib.request.urlopen('http://172.40.50.116/python.pdf')
fobj = open('/tmp/python.pdf', 'ab')
while True:
    data = html.read(4096)
    if not data:
        break
    fobj.write(data)
fobj.close()
```

### **再试一下**

```python	
url = 'https://img01.sogoucdn.com/app/a/100520021/ae21a29cb0aa339846f873a7ff5aa0a4'
html = request.urlopen(url)
with open('/tmp/girl.jpg','wb') as fobj:
     fobj.write(html.read())
```

### **安装wget**

```bash
#先安装pip3
sudo apt update
sudo apt install python3-pip
#安装wget
pip install wget
python3 -m venv mypy
sudo apt install python3.11 venv
source mypy/bin/activate
pip install wget
```

### 使用演示:

```python
import wget
wget.download('','')
```

## **案例7：爬取图片**

1.  将http://www.163.com所有的图片下载到本地
2.  本地的目录为/tmp/images
3.  图片名与网站上图片名保持一致

### get_web.py:

```python
import os
import wget
import re

def get_url(fname,patt):
    '用于在指定的文件中取出所有的模式,返回一个列表'
    result=[]
    cpatt=re.compile(patt)

    with open(fname) as fobj:
        for line in fobj:
            m=cpatt.search(line)
            if m:
                result.append(m.group())

```
### 续:

```python
if __name__=='__main__':
    path='/tmp/163'
    fname='/tmp/163/163.html'
    url='http://www.163.com'
    if not os.path.exists(path):
        os.mkdir(path)
    if not os.path.exists(fname):
        wget.download(url,fname)

    url_patt='(http|https:)//[\w.-]+\.(jpg|jpeg|png|gif)'
    img_list=get_url(fname,url_patt)
    print(img_list)
```

### 加入错误处理:

```python
...
import urllib.error
...
if __name__ == "__main__":
...
    for img_url in img_list:
        try:
            wget.download(img_url,path)
        except urllib.error.HTTPError as e:
            print('\n错误链接 %s', img_url)
        except Exception as e:
            print('下载错误')

```

